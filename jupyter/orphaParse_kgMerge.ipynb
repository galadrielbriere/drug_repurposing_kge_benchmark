{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger et parser le fichier XML\n",
    "tree = ET.parse('product6.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "# Initialiser une liste pour stocker les informations\n",
    "data = []\n",
    "\n",
    "# Parcourir tous les DrugRegulatoryStatus dans le fichier XML\n",
    "for drug_status in root.findall('DrugRegulatoryStatusList/DrugRegulatoryStatus'):\n",
    "    # Extraire l'ATC code (s'il existe)\n",
    "    # atc_code = drug_status.findtext('ATCCode', default='')\n",
    "    \n",
    "    # Extraire les informations de chaque Substance\n",
    "    for substance_association in drug_status.findall('SubstanceDrugRegulatoryStatusAssociationList/SubstanceDrugRegulatoryStatusAssociation'):\n",
    "        substance = substance_association.find('Substance')\n",
    "        \n",
    "        code = substance.findtext('Code', default='')\n",
    "        chemical_name = substance.findtext('ChemicalName', default='')\n",
    "        name = substance.findtext('Name', default='')\n",
    "        \n",
    "        # Extraire les OrphaCodes et noms des maladies associés\n",
    "        for disorder in drug_status.findall('DisorderList/Disorder'):\n",
    "            orpha_code = disorder.findtext('OrphaCode', default='')\n",
    "            disorder_name = disorder.findtext('Name', default='')\n",
    "            \n",
    "            # Extraire les informations de DrugTradeName (s'il y en a)\n",
    "            trade_names = []\n",
    "            for trade_name_association in drug_status.findall('DrugTradeNameDrugRegulatoryStatusAssociationList/DrugTradeNameDrugRegulatoryStatusAssociation'):\n",
    "                trade_name = trade_name_association.findtext('DrugTradeName', default='')\n",
    "                if trade_name:\n",
    "                    trade_names.append(trade_name)\n",
    "\n",
    "            # Si aucun nom commercial n'est trouvé, mettre une chaîne vide\n",
    "            trade_names_str = \", \".join(trade_names) if trade_names else ''\n",
    "            \n",
    "            # Ajouter les informations dans le tableau\n",
    "            data.append({\n",
    "                # 'ATCCode': atc_code,\n",
    "                'Code': code,\n",
    "                'ChemicalName': chemical_name,\n",
    "                'Name': name,\n",
    "                'DrugTradeName': trade_names_str,\n",
    "                'OrphaCode': orpha_code,\n",
    "                'DisorderName': disorder_name\n",
    "            })\n",
    "\n",
    "# Convertir les données en DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df['Name'] = df['Name'].str.lower()\n",
    "df['DisorderName'] = df['DisorderName'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5580, 6)\n",
      "(4915, 6)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df = df.drop_duplicates()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shep_kg = pd.read_csv(\"kg_giant_orphanet.csv\", sep=\",\", dtype={\"x_id\": str, \"y_id\": str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shep_kg[\"x_name_lower\"] = shep_kg['x_name'].str.lower()\n",
    "shep_kg[\"y_name_lower\"] = shep_kg['y_name'].str.lower()\n",
    "shep_kg[\"my_x_id\"] = shep_kg['x_type'].str.lower() + \"_\" + shep_kg[\"x_id\"]\n",
    "shep_kg[\"my_y_id\"] = shep_kg['y_type'].str.lower() + \"_\" + shep_kg[\"y_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bef = shep_kg.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Olmsted Syndrome 2 is duplicated with ids: ['disease_30961', 'disease_30965']. Removing all interactions with 'disease_30965' as x or y id.\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "print(\"Olmsted Syndrome 2 is duplicated with ids: ['disease_30961', 'disease_30965']. Removing all interactions with 'disease_30965' as x or y id.\")\n",
    "shep_kg = shep_kg[(shep_kg['my_x_id']!='disease_30965') & (shep_kg['my_y_id']!='disease_30965') ]\n",
    "print(bef - shep_kg.shape[0]) # Should be 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90271, 6)\n",
      "(134029, 6)\n",
      "Some nodes share the same id. Making my_id (node_type + id) the main id key.\n"
     ]
    }
   ],
   "source": [
    "# Extraire les colonnes nécessaires pour x et y, puis les concaténer\n",
    "x_info = shep_kg[['my_x_id', 'x_id', 'x_type', 'x_name', 'x_name_lower', 'x_source']].rename(\n",
    "    columns={'my_x_id': 'my_id','x_id': 'id', 'x_type': 'type', 'x_name': 'name', 'x_name_lower': 'name_lower', 'x_source': 'source'}\n",
    ")\n",
    "y_info = shep_kg[['my_y_id', 'y_id', 'y_type', 'y_name', \"y_name_lower\", 'y_source']].rename(\n",
    "    columns={'my_y_id': 'my_id', 'y_id': 'id', 'y_type': 'type', 'y_name': 'name', 'y_name_lower': 'name_lower', 'y_source': 'source'}\n",
    ")\n",
    "\n",
    "# Concaténer les informations de x et y\n",
    "combined_info = pd.concat([x_info, y_info], ignore_index=True)\n",
    "\n",
    "# Supprimer les doublons en fonction de l'ID pour créer le node_map\n",
    "node_map = combined_info.drop_duplicates(subset='id').reset_index(drop=True)\n",
    "print(node_map.shape)\n",
    "node_map = combined_info.drop_duplicates(subset='my_id').reset_index(drop=True)\n",
    "print(node_map.shape)\n",
    "print(\"Some nodes share the same id. Making my_id (node_type + id) the main id key.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_map_drug_diseases = node_map[node_map[\"type\"].isin(['drug', 'disease'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>my_id</th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>name_lower</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [my_id, id, type, name, name_lower, source]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_unique_names = node_map_drug_diseases[node_map_drug_diseases['name'].duplicated(keep=False)]\n",
    "non_unique_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_disease_kg = shep_kg[(shep_kg['my_x_id'].isin(node_map_drug_diseases['my_id'])) | (shep_kg['my_y_id'].isin(node_map_drug_diseases['my_id']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer node_map_drug_diseases pour ne garder que les lignes où 'type' est 'drug'\n",
    "tmp = node_map_drug_diseases[node_map_drug_diseases[\"type\"] == \"drug\"]\n",
    "# Créer le dictionnaire avec 'name_lower' comme clé et 'my_id' comme valeur\n",
    "kg_drug_names_dict = dict(zip(tmp['name_lower'], tmp['my_id']))\n",
    "# Et inversement\n",
    "kg_drug_ids_dict = dict(zip(tmp['my_id'], tmp['name_lower']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer node_map_drug_diseases pour ne garder que les lignes où 'type' est 'disease'\n",
    "tmp = node_map_drug_diseases[node_map_drug_diseases[\"type\"] == \"disease\"]\n",
    "# Créer le dictionnaire avec 'name_lower' comme clé et 'my_id' comme valeur\n",
    "kg_diseases_names_dict = dict(zip(tmp['name_lower'], tmp['my_id']))\n",
    "# Et inversement\n",
    "kg_diseases_ids_dict = dict(zip(tmp['my_id'], tmp['name_lower']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Inverser le dictionnaire pour regrouper les clés par valeurs\n",
    "value_to_keys = defaultdict(list)\n",
    "for key, value in kg_diseases_ids_dict.items():\n",
    "    value_to_keys[value].append(key)\n",
    "\n",
    "# Identifier et afficher les valeurs dupliquées\n",
    "duplicates = {value: keys for value, keys in value_to_keys.items() if len(keys) > 1}\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['drug_kg_id'] = df['Name'].map(kg_drug_names_dict)\n",
    "df['disease_kg_id'] = df['DisorderName'].map(kg_diseases_names_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df.dropna(subset=['drug_kg_id', 'disease_kg_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['drug']\n",
      "['disease']\n"
     ]
    }
   ],
   "source": [
    "drug_disease_pairs_kg = drug_disease_kg[\n",
    "    ((drug_disease_kg['x_type'] == 'disease') & (drug_disease_kg['y_type'] == 'drug')) |\n",
    "    ((drug_disease_kg['y_type'] == 'disease') & (drug_disease_kg['x_type'] == 'drug'))\n",
    "]\n",
    "\n",
    "print(drug_disease_pairs_kg['x_type'].unique())\n",
    "print(drug_disease_pairs_kg['y_type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40041\n",
      "829\n"
     ]
    }
   ],
   "source": [
    "in_kg = drug_disease_pairs_kg[['my_x_id', 'my_y_id']]\n",
    "in_orpha = filtered_df[['drug_kg_id', 'disease_kg_id']]\n",
    "print(in_kg.shape[0])\n",
    "print(in_orpha.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(829, 8)\n",
      "(829, 8)\n",
      "(829, 2)\n"
     ]
    }
   ],
   "source": [
    "print(filtered_df.shape)\n",
    "print(filtered_df.drop_duplicates().shape)\n",
    "print(filtered_df[['drug_kg_id', 'disease_kg_id']].drop_duplicates().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(829, 2)\n",
      "(829, 2)\n",
      "829\n"
     ]
    }
   ],
   "source": [
    "print(in_orpha.shape)\n",
    "print(in_orpha.drop_duplicates().shape)\n",
    "orpha_combinations = set(zip(in_orpha['drug_kg_id'], in_orpha['disease_kg_id']))\n",
    "print(len(orpha_combinations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "829\n",
      "5471423\n",
      "665\n",
      "164\n"
     ]
    }
   ],
   "source": [
    "# Créer un ensemble de combinaisons de in_orpha\n",
    "orpha_combinations = set(zip(in_orpha['drug_kg_id'], in_orpha['disease_kg_id']))\n",
    "\n",
    "# Créer un ensemble de combinaisons de shep_kg\n",
    "kg_combinations = set(zip(shep_kg['my_x_id'], shep_kg['my_y_id']))\n",
    "\n",
    "# Identifier les combinaisons qui sont dans orpha mais pas dans shep_kg\n",
    "missing_combinations = orpha_combinations - kg_combinations\n",
    "\n",
    "# Identifier les combinaisons qui sont dans orpha et dans shep_kg\n",
    "already_in_combinations = orpha_combinations - missing_combinations\n",
    "\n",
    "print(len(orpha_combinations))\n",
    "print(len(kg_combinations))\n",
    "print(len(missing_combinations))\n",
    "print(len(already_in_combinations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(665, 14)\n"
     ]
    }
   ],
   "source": [
    "# Préparer le DataFrame not_in_kg\n",
    "not_in_kg = []\n",
    "\n",
    "for drug_id, disease_id in missing_combinations:\n",
    "    # Récupérer les infos pour le drug et le disease\n",
    "    drug_info = node_map_drug_diseases[node_map_drug_diseases['my_id'] == drug_id].iloc[0]\n",
    "    disease_info = node_map_drug_diseases[node_map_drug_diseases['my_id'] == disease_id].iloc[0]\n",
    "    \n",
    "    # Créer une nouvelle ligne pour not_in_kg\n",
    "    new_row = {\n",
    "        'relation': 'orpha_treatment',\n",
    "        'display_relation': 'orpha_treatment',\n",
    "        'x_id': drug_info['id'] if drug_info['type'] == 'drug' else disease_info['id'],\n",
    "        'x_type': drug_info['type'] if drug_info['type'] == 'drug' else disease_info['type'],\n",
    "        'x_name': drug_info['name'] if drug_info['type'] == 'drug' else disease_info['name'],\n",
    "        'x_source': drug_info['source'] if drug_info['type'] == 'drug' else disease_info['source'],\n",
    "        'y_id': disease_info['id'] if disease_info['type'] == 'disease' else drug_info['id'],\n",
    "        'y_type': disease_info['type'] if disease_info['type'] == 'disease' else drug_info['type'],\n",
    "        'y_name': disease_info['name'] if disease_info['type'] == 'disease' else drug_info['name'],\n",
    "        'y_source': disease_info['source'] if disease_info['type'] == 'disease' else drug_info['source'],\n",
    "        'x_name_lower': drug_info['name_lower'] if drug_info['type'] == 'drug' else disease_info['name_lower'],\n",
    "        'y_name_lower': disease_info['name_lower'] if disease_info['type'] == 'disease' else drug_info['name_lower'],\n",
    "        'my_x_id': drug_id,\n",
    "        'my_y_id': disease_id\n",
    "    }\n",
    "    \n",
    "    # Ajouter la nouvelle ligne à la liste\n",
    "    not_in_kg.append(new_row)\n",
    "\n",
    "# Convertir la liste en DataFrame\n",
    "not_in_kg = pd.DataFrame(not_in_kg)\n",
    "print(not_in_kg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(164, 14)\n"
     ]
    }
   ],
   "source": [
    "# Préparer le DataFrame already_in_kg\n",
    "already_in_kg = []\n",
    "\n",
    "for drug_id, disease_id in already_in_combinations:\n",
    "    # Récupérer les infos pour le drug et le disease\n",
    "    drug_info = node_map_drug_diseases[node_map_drug_diseases['my_id'] == drug_id].iloc[0]\n",
    "    disease_info = node_map_drug_diseases[node_map_drug_diseases['my_id'] == disease_id].iloc[0]\n",
    "    \n",
    "    # Créer une nouvelle ligne pour not_in_kg\n",
    "    new_row = {\n",
    "        'relation': 'orpha_treatment',\n",
    "        'display_relation': 'orpha_treatment',\n",
    "        'x_id': drug_info['id'] if drug_info['type'] == 'drug' else disease_info['id'],\n",
    "        'x_type': drug_info['type'] if drug_info['type'] == 'drug' else disease_info['type'],\n",
    "        'x_name': drug_info['name'] if drug_info['type'] == 'drug' else disease_info['name'],\n",
    "        'x_source': drug_info['source'] if drug_info['type'] == 'drug' else disease_info['source'],\n",
    "        'y_id': disease_info['id'] if disease_info['type'] == 'disease' else drug_info['id'],\n",
    "        'y_type': disease_info['type'] if disease_info['type'] == 'disease' else drug_info['type'],\n",
    "        'y_name': disease_info['name'] if disease_info['type'] == 'disease' else drug_info['name'],\n",
    "        'y_source': disease_info['source'] if disease_info['type'] == 'disease' else drug_info['source'],\n",
    "        'x_name_lower': drug_info['name_lower'] if drug_info['type'] == 'drug' else disease_info['name_lower'],\n",
    "        'y_name_lower': disease_info['name_lower'] if disease_info['type'] == 'disease' else drug_info['name_lower'],\n",
    "        'my_x_id': drug_id,\n",
    "        'my_y_id': disease_id\n",
    "    }\n",
    "    \n",
    "    # Ajouter la nouvelle ligne à la liste\n",
    "    already_in_kg.append(new_row)\n",
    "\n",
    "# Convertir la liste en DataFrame\n",
    "already_in_kg = pd.DataFrame(already_in_kg)\n",
    "print(already_in_kg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_shep_kg = shep_kg[~shep_kg.apply(lambda row: (row['my_x_id'], row['my_y_id']) in orpha_combinations, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_shep_kg = pd.concat([filtered_shep_kg, already_in_kg, not_in_kg], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "display_relation\n",
       "synergistic interaction    2672628\n",
       "expression present         1518203\n",
       "interacts with              343275\n",
       "ppi                         321075\n",
       "phenotype present           204766\n",
       "parent-child                147108\n",
       "associated with              96817\n",
       "side effect                  79137\n",
       "contraindication             28884\n",
       "expression absent            19887\n",
       "target                       16380\n",
       "indication                    8533\n",
       "enzyme                        5317\n",
       "transporter                   3092\n",
       "off-label use                 2457\n",
       "linked to                     1795\n",
       "phenotype absent              1483\n",
       "carrier                        864\n",
       "orpha_treatment                829\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_shep_kg[\"display_relation\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_shep_kg.to_csv(\"shep_kg_with_orphan_treatments.csv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer pour obtenir les x_id avec display_relation == \"orpha_treat\"\n",
    "orpha_treat_ids = final_shep_kg[final_shep_kg['display_relation'] == 'orpha_treatment']['my_x_id'].unique()\n",
    "\n",
    "# Filtrer pour obtenir les lignes avec display_relation == \"treatment\" pour les x_id filtrés\n",
    "treatment_counts = final_shep_kg[(final_shep_kg['my_x_id'].isin(orpha_treat_ids)) & (final_shep_kg['display_relation'] == 'indication')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "display_relation\n",
       "synergistic interaction    233174\n",
       "side effect                  9878\n",
       "contraindication             2297\n",
       "indication                   1546\n",
       "target                       1206\n",
       "orpha_treatment               829\n",
       "enzyme                        750\n",
       "transporter                   381\n",
       "off-label use                 320\n",
       "carrier                        93\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_shep_kg[final_shep_kg['my_x_id'].isin(orpha_treat_ids)][\"display_relation\"].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
