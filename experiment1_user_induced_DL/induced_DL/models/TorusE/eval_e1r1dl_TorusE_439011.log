2024-10-28 16:10:37,398 - WARNING - /linkhome/rech/genuyp01/ufq76hz/.conda/envs/torch_pyg/lib/python3.10/site-packages/ignite/handlers/checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.
  from torch.distributed.optim import ZeroRedundancyOptimizer

2024-10-28 16:10:37,570 - INFO - Configuration loaded:
{
    "common": {
        "seed": 42,
        "input_pkl": "/lustre/fswork/projects/rech/rnk/ufq76hz/dr_benchmark/experiment1_user_induced_DL/induced_DL/kg_processing/kg.pkl",
        "out": "./",
        "verbose": true,
        "run_kg_prep": false,
        "run_training": false,
        "run_evaluation": true,
        "plot_training_metrics": true
    },
    "model": {
        "name": "TorusE",
        "emb_dim": 200,
        "margin": 1
    },
    "sampler": {
        "name": "Mixed",
        "n_neg": 5
    },
    "optimizer": {
        "name": "Adam",
        "params": {
            "lr": 0.001,
            "weight_decay": 0.001
        }
    },
    "training": {
        "max_epochs": 1000,
        "batch_size": 4096,
        "eval_interval": 20,
        "eval_batch_size": 40,
        "patience": 20
    }
}
2024-10-28 16:10:37,570 - INFO - Setting number of threads to 3
2024-10-28 16:10:37,788 - INFO - Loading parameters from params.yaml
2024-10-28 16:10:37,788 - INFO - Output folder: ./
2024-10-28 16:10:37,789 - INFO - Loading KG...
2024-10-28 16:10:37,789 - INFO - Will not run the preparation step. Using KG stored in: /lustre/fswork/projects/rech/rnk/ufq76hz/dr_benchmark/experiment1_user_induced_DL/induced_DL/kg_processing/kg.pkl
2024-10-28 16:11:36,706 - INFO - Done
2024-10-28 16:11:36,707 - INFO - Detected device: cuda
2024-10-28 16:11:36,715 - INFO - Initializing model...
2024-10-28 16:11:36,715 - WARNING - /lustre/fswork/projects/rech/rnk/ufq76hz/dr_benchmark/dev/run_training.py:133: UserWarning: The 'dissimilarity' field is missing for model TorusE. Defaulting to 'torus_L2'.
  warnings.warn(f"The 'dissimilarity' field is missing for model {model_name}. Defaulting to 'torus_L2'.")

2024-10-28 16:11:38,312 - INFO - Optimizer 'Adam' initialized with parameters: {'lr': 0.001, 'weight_decay': 0.001}
2024-10-28 16:11:38,313 - INFO - Initializing sampler...
2024-10-28 16:12:42,176 - WARNING - /lustre/fswork/projects/rech/rnk/ufq76hz/dr_benchmark/dev/run_training.py:302: UserWarning: No learning rate scheduler specified in the configuration.
  warnings.warn("No learning rate scheduler specified in the configuration.")

2024-10-28 16:12:42,205 - INFO - Number of training batches: 1141
2024-10-28 16:12:42,322 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2024-10-28 16:12:42,326 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2024-10-28 16:12:46,479 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2024-10-28 16:12:46,480 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2024-10-28 16:12:57,575 - WARNING - /lustre/fswork/projects/rech/rnk/ufq76hz/dr_benchmark/dev/run_training.py:133: UserWarning: The 'dissimilarity' field is missing for model TorusE. Defaulting to 'torus_L2'.
  warnings.warn(f"The 'dissimilarity' field is missing for model {model_name}. Defaulting to 'torus_L2'.")

2024-10-28 16:12:58,039 - INFO - Loading best model.
2024-10-28 16:12:58,040 - INFO - Best model is ./checkpoints/best_model_checkpoint_val_mrr=0.0916.pt
2024-10-28 16:12:58,041 - WARNING - /lustre/fswork/projects/rech/rnk/ufq76hz/dr_benchmark/dev/run_training.py:760: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(checkpoint_dir, best_model))

2024-10-28 16:12:58,817 - INFO - Best model successfully loaded.
2024-10-28 16:12:58,817 - INFO - Evaluating on the test set with best model...
2024-10-28 16:12:58,817 - INFO - Calculating MRR for List 1...
Link prediction evaluation:   0%|          | 0/4176 [00:00<?, ?batch/s]Link prediction evaluation:   0%|          | 0/4176 [00:02<?, ?batch/s]
2024-10-28 16:13:01,129 - INFO - Error processing relation 'drug_drug': CUDA out of memory. Tried to allocate 3.20 GiB. GPU 0 has a total capacity of 31.73 GiB of which 2.07 GiB is free. Including non-PyTorch memory, this process has 29.66 GiB memory in use. Of the allocated memory 26.11 GiB is allocated by PyTorch, and 3.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Link prediction evaluation:   0%|          | 0/108 [00:00<?, ?batch/s]Link prediction evaluation:   0%|          | 0/108 [00:00<?, ?batch/s]
2024-10-28 16:13:01,207 - INFO - Error processing relation 'disease_disease': CUDA out of memory. Tried to allocate 3.20 GiB. GPU 0 has a total capacity of 31.73 GiB of which 2.07 GiB is free. Including non-PyTorch memory, this process has 29.66 GiB memory in use. Of the allocated memory 26.10 GiB is allocated by PyTorch, and 3.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Link prediction evaluation:   0%|          | 0/1004 [00:00<?, ?batch/s]Link prediction evaluation:   0%|          | 0/1004 [00:00<?, ?batch/s]
2024-10-28 16:13:01,306 - INFO - Error processing relation 'protein_protein': CUDA out of memory. Tried to allocate 3.20 GiB. GPU 0 has a total capacity of 31.73 GiB of which 2.07 GiB is free. Including non-PyTorch memory, this process has 29.66 GiB memory in use. Of the allocated memory 26.10 GiB is allocated by PyTorch, and 3.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Link prediction evaluation:   0%|          | 0/4176 [00:00<?, ?batch/s]Link prediction evaluation:   0%|          | 0/4176 [00:00<?, ?batch/s]
2024-10-28 16:13:01,404 - INFO - Error processing relation 'drug_drug_inv': CUDA out of memory. Tried to allocate 3.20 GiB. GPU 0 has a total capacity of 31.73 GiB of which 2.07 GiB is free. Including non-PyTorch memory, this process has 29.66 GiB memory in use. Of the allocated memory 26.11 GiB is allocated by PyTorch, and 3.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Link prediction evaluation:   0%|          | 0/108 [00:00<?, ?batch/s]Link prediction evaluation:   0%|          | 0/108 [00:00<?, ?batch/s]
2024-10-28 16:13:01,500 - INFO - Error processing relation 'disease_disease_inv': CUDA out of memory. Tried to allocate 3.20 GiB. GPU 0 has a total capacity of 31.73 GiB of which 2.07 GiB is free. Including non-PyTorch memory, this process has 29.66 GiB memory in use. Of the allocated memory 26.10 GiB is allocated by PyTorch, and 3.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Link prediction evaluation:   0%|          | 0/1004 [00:00<?, ?batch/s]Link prediction evaluation:   0%|          | 0/1004 [00:00<?, ?batch/s]
2024-10-28 16:13:01,596 - INFO - Error processing relation 'protein_protein_inv': CUDA out of memory. Tried to allocate 3.20 GiB. GPU 0 has a total capacity of 31.73 GiB of which 2.07 GiB is free. Including non-PyTorch memory, this process has 29.66 GiB memory in use. Of the allocated memory 26.10 GiB is allocated by PyTorch, and 3.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2024-10-28 16:13:01,596 - INFO - Calculating MRR for List 2...
Link prediction evaluation:   0%|          | 0/27 [00:00<?, ?batch/s]Link prediction evaluation:   0%|          | 0/27 [00:00<?, ?batch/s]
2024-10-28 16:13:01,694 - INFO - Error processing relation 'indication': CUDA out of memory. Tried to allocate 3.20 GiB. GPU 0 has a total capacity of 31.73 GiB of which 2.07 GiB is free. Including non-PyTorch memory, this process has 29.66 GiB memory in use. Of the allocated memory 26.10 GiB is allocated by PyTorch, and 3.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2024-10-28 16:13:01,695 - INFO - Calculating MRR for Remaining Relations...
Link prediction evaluation:   0%|          | 0/452 [00:00<?, ?batch/s]Link prediction evaluation:   0%|          | 0/452 [00:00<?, ?batch/s]
2024-10-28 16:13:01,794 - INFO - Error processing relation 'protein_bioprocess': CUDA out of memory. Tried to allocate 3.20 GiB. GPU 0 has a total capacity of 31.73 GiB of which 2.07 GiB is free. Including non-PyTorch memory, this process has 29.66 GiB memory in use. Of the allocated memory 26.10 GiB is allocated by PyTorch, and 3.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Link prediction evaluation:   0%|          | 0/62 [00:00<?, ?batch/s]Link prediction evaluation:   0%|          | 0/62 [00:00<?, ?batch/s]
2024-10-28 16:13:01,892 - INFO - Error processing relation 'protein_absent_anatomy': CUDA out of memory. Tried to allocate 3.20 GiB. GPU 0 has a total capacity of 31.73 GiB of which 2.07 GiB is free. Including non-PyTorch memory, this process has 29.66 GiB memory in use. Of the allocated memory 26.10 GiB is allocated by PyTorch, and 3.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Link prediction evaluation:   0%|          | 0/260 [00:00<?, ?batch/s]Link prediction evaluation:   0%|          | 0/260 [00:00<?, ?batch/s]
2024-10-28 16:13:01,991 - INFO - Error processing relation 'protein_cellcomp': CUDA out of memory. Tried to allocate 3.20 GiB. GPU 0 has a total capacity of 31.73 GiB of which 2.07 GiB is free. Including non-PyTorch memory, this process has 29.66 GiB memory in use. Of the allocated memory 26.10 GiB is allocated by PyTorch, and 3.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Link prediction evaluation:   0%|          | 0/1 [00:00<?, ?batch/s]Link prediction evaluation: 100%|██████████| 1/1 [00:00<00:00, 44.59batch/s]
2024-10-28 16:13:02,077 - INFO - MRR for relation 'exposure_molfunc': 0.0377
Link prediction evaluation:   0%|          | 0/8 [00:00<?, ?batch/s]Link prediction evaluation:   0%|          | 0/8 [00:00<?, ?batch/s]
2024-10-28 16:13:02,150 - INFO - Error processing relation 'pathway_pathway': CUDA out of memory. Tried to allocate 3.20 GiB. GPU 0 has a total capacity of 31.73 GiB of which 2.07 GiB is free. Including non-PyTorch memory, this process has 29.66 GiB memory in use. Of the allocated memory 26.10 GiB is allocated by PyTorch, and 3.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Link prediction evaluation:   0%|          | 0/134 [00:00<?, ?batch/s]Link prediction evaluation:   0%|          | 0/134 [00:00<?, ?batch/s]
2024-10-28 16:13:02,249 - INFO - Error processing relation 'protein_pathway': CUDA out of memory. Tried to allocate 3.20 GiB. GPU 0 has a total capacity of 31.73 GiB of which 2.07 GiB is free. Including non-PyTorch memory, this process has 29.66 GiB memory in use. Of the allocated memory 26.10 GiB is allocated by PyTorch, and 3.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Link prediction evaluation:   0%|          | 0/4 [00:00<?, ?batch/s]Link prediction evaluation:   0%|          | 0/4 [00:00<?, ?batch/s]
2024-10-28 16:13:02,352 - INFO - Error processing relation 'exposure_protein': CUDA out of memory. Tried to allocate 3.20 GiB. GPU 0 has a total capacity of 31.73 GiB of which 2.07 GiB is free. Including non-PyTorch memory, this process has 29.66 GiB memory in use. Of the allocated memory 26.10 GiB is allocated by PyTorch, and 3.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Link prediction evaluation:   0%|          | 0/217 [00:00<?, ?batch/s]Link prediction evaluation:   0%|          | 0/217 [00:00<?, ?batch/s]
2024-10-28 16:13:02,448 - INFO - Error processing relation 'protein_molfunc': CUDA out of memory. Tried to allocate 3.20 GiB. GPU 0 has a total capacity of 31.73 GiB of which 2.07 GiB is free. Including non-PyTorch memory, this process has 29.66 GiB memory in use. Of the allocated memory 26.10 GiB is allocated by PyTorch, and 3.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Link prediction evaluation:   0%|          | 0/33 [00:00<?, ?batch/s]Link prediction evaluation:   0%|          | 0/33 [00:00<?, ?batch/s]
2024-10-28 16:13:02,547 - INFO - Error processing relation 'phenotype_protein': CUDA out of memory. Tried to allocate 3.20 GiB. GPU 0 has a total capacity of 31.73 GiB of which 2.07 GiB is free. Including non-PyTorch memory, this process has 29.66 GiB memory in use. Of the allocated memory 26.10 GiB is allocated by PyTorch, and 3.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Link prediction evaluation:   0%|          | 0/6 [00:00<?, ?batch/s]Link prediction evaluation:   0%|          | 0/6 [00:00<?, ?batch/s]
2024-10-28 16:13:02,646 - INFO - Error processing relation 'exposure_bioprocess': CUDA out of memory. Tried to allocate 3.20 GiB. GPU 0 has a total capacity of 31.73 GiB of which 2.07 GiB is free. Including non-PyTorch memory, this process has 29.66 GiB memory in use. Of the allocated memory 26.10 GiB is allocated by PyTorch, and 3.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Link prediction evaluation:   0%|          | 0/639 [00:00<?, ?batch/s]Link prediction evaluation:   0%|          | 0/639 [00:00<?, ?batch/s]
2024-10-28 16:13:02,746 - INFO - Error processing relation 'disease_phenotype_positive': CUDA out of memory. Tried to allocate 3.20 GiB. GPU 0 has a total capacity of 31.73 GiB of which 2.07 GiB is free. Including non-PyTorch memory, this process has 29.66 GiB memory in use. Of the allocated memory 26.10 GiB is allocated by PyTorch, and 3.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Link prediction evaluation:   0%|          | 0/1 [00:00<?, ?batch/s]Link prediction evaluation: 100%|██████████| 1/1 [00:00<00:00, 75.19batch/s]
2024-10-28 16:13:02,793 - INFO - MRR for relation 'exposure_cellcomp': 0.0000
Link prediction evaluation:   0%|          | 0/9 [00:00<?, ?batch/s]Link prediction evaluation:   0%|          | 0/9 [00:00<?, ?batch/s]
2024-10-28 16:13:02,902 - INFO - Error processing relation 'cellcomp_cellcomp': CUDA out of memory. Tried to allocate 3.20 GiB. GPU 0 has a total capacity of 31.73 GiB of which 2.07 GiB is free. Including non-PyTorch memory, this process has 29.66 GiB memory in use. Of the allocated memory 26.10 GiB is allocated by PyTorch, and 3.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Link prediction evaluation:   0%|          | 0/146 [00:00<?, ?batch/s]Link prediction evaluation:   0%|          | 0/146 [00:00<?, ?batch/s]
2024-10-28 16:13:02,976 - INFO - Error processing relation 'bioprocess_bioprocess': CUDA out of memory. Tried to allocate 3.20 GiB. GPU 0 has a total capacity of 31.73 GiB of which 2.07 GiB is free. Including non-PyTorch memory, this process has 29.66 GiB memory in use. Of the allocated memory 26.10 GiB is allocated by PyTorch, and 3.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Link prediction evaluation:   0%|          | 0/248 [00:00<?, ?batch/s]Link prediction evaluation:   0%|          | 0/248 [00:00<?, ?batch/s]
2024-10-28 16:13:03,075 - INFO - Error processing relation 'drug_effect': CUDA out of memory. Tried to allocate 3.20 GiB. GPU 0 has a total capacity of 31.73 GiB of which 2.07 GiB is free. Including non-PyTorch memory, this process has 29.66 GiB memory in use. Of the allocated memory 26.10 GiB is allocated by PyTorch, and 3.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Link prediction evaluation:   0%|          | 0/9 [00:00<?, ?batch/s]Link prediction evaluation:   0%|          | 0/9 [00:00<?, ?batch/s]
2024-10-28 16:13:03,172 - INFO - Error processing relation 'anatomy_anatomy': CUDA out of memory. Tried to allocate 3.20 GiB. GPU 0 has a total capacity of 31.73 GiB of which 2.07 GiB is free. Including non-PyTorch memory, this process has 29.66 GiB memory in use. Of the allocated memory 26.10 GiB is allocated by PyTorch, and 3.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Link prediction evaluation:   0%|          | 0/270 [00:00<?, ?batch/s]Link prediction evaluation:   0%|          | 0/270 [00:00<?, ?batch/s]
2024-10-28 16:13:03,271 - INFO - Error processing relation 'disease_protein': CUDA out of memory. Tried to allocate 3.20 GiB. GPU 0 has a total capacity of 31.73 GiB of which 2.07 GiB is free. Including non-PyTorch memory, this process has 29.66 GiB memory in use. Of the allocated memory 26.10 GiB is allocated by PyTorch, and 3.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Link prediction evaluation:   0%|          | 0/6 [00:00<?, ?batch/s]Link prediction evaluation:   0%|          | 0/6 [00:00<?, ?batch/s]
2024-10-28 16:13:03,370 - INFO - Error processing relation 'exposure_disease': CUDA out of memory. Tried to allocate 3.20 GiB. GPU 0 has a total capacity of 31.73 GiB of which 2.07 GiB is free. Including non-PyTorch memory, this process has 29.66 GiB memory in use. Of the allocated memory 26.10 GiB is allocated by PyTorch, and 3.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Link prediction evaluation:   0%|          | 0/71 [00:00<?, ?batch/s]Link prediction evaluation:   0%|          | 0/71 [00:00<?, ?batch/s]
2024-10-28 16:13:03,470 - INFO - Error processing relation 'drug_protein': CUDA out of memory. Tried to allocate 3.20 GiB. GPU 0 has a total capacity of 31.73 GiB of which 2.07 GiB is free. Including non-PyTorch memory, this process has 29.66 GiB memory in use. Of the allocated memory 26.10 GiB is allocated by PyTorch, and 3.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Link prediction evaluation:   0%|          | 0/8 [00:00<?, ?batch/s]Link prediction evaluation:   0%|          | 0/8 [00:00<?, ?batch/s]
2024-10-28 16:13:03,568 - INFO - Error processing relation 'off-label use': CUDA out of memory. Tried to allocate 3.20 GiB. GPU 0 has a total capacity of 31.73 GiB of which 2.07 GiB is free. Including non-PyTorch memory, this process has 29.66 GiB memory in use. Of the allocated memory 26.10 GiB is allocated by PyTorch, and 3.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Link prediction evaluation:   0%|          | 0/56 [00:00<?, ?batch/s]Link prediction evaluation:   0%|          | 0/56 [00:00<?, ?batch/s]
2024-10-28 16:13:03,667 - INFO - Error processing relation 'phenotype_phenotype': CUDA out of memory. Tried to allocate 3.20 GiB. GPU 0 has a total capacity of 31.73 GiB of which 2.07 GiB is free. Including non-PyTorch memory, this process has 29.66 GiB memory in use. Of the allocated memory 26.10 GiB is allocated by PyTorch, and 3.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Link prediction evaluation:   0%|          | 0/25 [00:00<?, ?batch/s]Link prediction evaluation:   0%|          | 0/25 [00:00<?, ?batch/s]
2024-10-28 16:13:03,773 - INFO - Error processing relation 'molfunc_molfunc': CUDA out of memory. Tried to allocate 3.20 GiB. GPU 0 has a total capacity of 31.73 GiB of which 2.07 GiB is free. Including non-PyTorch memory, this process has 29.66 GiB memory in use. Of the allocated memory 26.10 GiB is allocated by PyTorch, and 3.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Link prediction evaluation:   0%|          | 0/91 [00:00<?, ?batch/s]Link prediction evaluation:   0%|          | 0/91 [00:00<?, ?batch/s]
2024-10-28 16:13:03,866 - INFO - Error processing relation 'contraindication': CUDA out of memory. Tried to allocate 3.20 GiB. GPU 0 has a total capacity of 31.73 GiB of which 2.07 GiB is free. Including non-PyTorch memory, this process has 29.66 GiB memory in use. Of the allocated memory 26.10 GiB is allocated by PyTorch, and 3.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Link prediction evaluation:   0%|          | 0/7 [00:00<?, ?batch/s]Link prediction evaluation:   0%|          | 0/7 [00:00<?, ?batch/s]
2024-10-28 16:13:03,966 - INFO - Error processing relation 'exposure_exposure': CUDA out of memory. Tried to allocate 3.20 GiB. GPU 0 has a total capacity of 31.73 GiB of which 2.07 GiB is free. Including non-PyTorch memory, this process has 29.66 GiB memory in use. Of the allocated memory 26.10 GiB is allocated by PyTorch, and 3.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Link prediction evaluation:   0%|          | 0/5 [00:00<?, ?batch/s]Link prediction evaluation:   0%|          | 0/5 [00:00<?, ?batch/s]
2024-10-28 16:13:04,065 - INFO - Error processing relation 'disease_phenotype_negative': CUDA out of memory. Tried to allocate 3.20 GiB. GPU 0 has a total capacity of 31.73 GiB of which 2.07 GiB is free. Including non-PyTorch memory, this process has 29.66 GiB memory in use. Of the allocated memory 26.10 GiB is allocated by PyTorch, and 3.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Link prediction evaluation:   0%|          | 0/4738 [00:00<?, ?batch/s]Link prediction evaluation:   0%|          | 0/4738 [00:00<?, ?batch/s]
2024-10-28 16:13:04,166 - INFO - Error processing relation 'protein_present_anatomy': CUDA out of memory. Tried to allocate 3.20 GiB. GPU 0 has a total capacity of 31.73 GiB of which 2.07 GiB is free. Including non-PyTorch memory, this process has 29.66 GiB memory in use. Of the allocated memory 26.11 GiB is allocated by PyTorch, and 3.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2024-10-28 16:13:04,207 - INFO - Results saved to ./evaluation_metrics.yaml
2024-10-28 16:13:04,208 - INFO - Final Test MRR with best model: 0.014861857475697241
